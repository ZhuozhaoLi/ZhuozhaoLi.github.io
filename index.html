<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Zhuozhao  Li</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="/assets/img/sustech-icon.png" type="image/x-icon">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83378729-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-83378729-3');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:%6C%69%7A%7A@%73%75%73%74%65%63%68.%65%64%75.%63%6E"><i class="fas fa-envelope"></i></a>
<a href="https://orcid.org/0000-0003-1903-6428" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
<a href="https://scholar.google.com/citations?user=6lgtiL8AAAAJ&hl=en" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/ZhuozhaoLi" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/zhuozhao-li-6467042a" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>











        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/awards/">
                Awards
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/openings/">
                Openings
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/research/">
                Research
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/services/">
                Services
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h2 class="post-title">
     <span class="font-weight-bold">Zhuozhao</span>  <span class="font-weight-bold">Li</span>
    </h2>
    <p class="post-description">Assistant Professor, Southern University of Science and Technology</p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg">
      
      
        <div class="address">
          <p>Office 516, South Tower, CoE Building</p> <p>Department of Computer Science and Engineering</p> <p>Southern University of Science and Technology</p> <p>1088 Xueyuan Avenue, Nanshan District</p> <p>Shenzhen 518055, China</p>

        </div>
      
      
        <div class="social">
          <div class="contact-icons">
            <a href="mailto:%6C%69%7A%7A@%73%75%73%74%65%63%68.%65%64%75.%63%6E"><i class="fas fa-envelope"></i></a>
<a href="https://orcid.org/0000-0003-1903-6428" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
<a href="https://scholar.google.com/citations?user=6lgtiL8AAAAJ&hl=en" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/ZhuozhaoLi" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/zhuozhao-li-6467042a" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>











          </div>
          <div class="contact-note">Email is the best way to contact me.
</div>
        </div>
    
    </div>
    

    <div class="clearfix">
      <p>I am an assistant professor in the <a href="http://cse.sustech.edu.cn/" target="\_blank">Department of Computer Science and Engineering</a> at <a href="https://www.sustech.edu.cn/" target="\_blank">Southern University of Science and Technology</a> (SUSTech), Shenzhen, China.
Before joining SUSTech, I was a postdoc in <a href="http://labs.globus.org/" target="\_blank">Globus Lab</a> at the <a href="https://www.uchicago.edu/" target="\_blank">University of Chicago</a>, hosted by <a href="http://www.ianfoster.org/" target="\_blank">Ian Foster</a> and <a href="https://kylechard.com/" target="\_blank">Kyle Chard</a>. I earned my Ph.D. in the <a href="http://www.cs.virginia.edu/" target="\_blank">Department of Computer Science</a> at the <a href="http://www.virginia.edu/" target="\_blank">University of Virginia</a> in May 2018, under the supervision of <a href="http://www.cs.virginia.edu/~hs6ms/" target="\_blank">Haiying Shen</a>.
I received the B.E. degree <!--- in [Optical Engineering](http://opt.zju.edu.cn/english/){:target="\_blank"} --->
from <a href="http://www.zju.edu.cn/english/" target="\_blank">Zhejiang University</a>, China in 2010,
and the M.S. degree <!--- in [Electrical Engineering](http://ee.usc.edu/){:target="\_blank"} --->
from <a href="http://www.usc.edu/" target="\_blank">University of Southern California</a>, USA in 2012.</p>

<p>My research interests include High Performance Computing, Distributed Systems, Cloud/Edge Computing, and Internet of Things.
Please refer to my <a href="assets/CV-ZhuozhaoLi.pdf" target="\_blank">CV</a> for more information.</p>

<p><strong>I am looking for self-motivated students, postdocs, and research assistant professors. If you are interested in doing research about HPC, distributed systems, and cloud computing with me, please refer to the <a href="https://zhuozhaoli.github.io/openings/">openings</a> for more details.</strong></p>

    </div>

    
      <div class="news">
  <h2>Recent News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Nov 18, 2021</th>
          <td>
            
              Check out the multi-lab effort for COVID drug screening <a href="/assets/pdf/JCIM-clyde-covid-2021.pdf">High-Throughput Virtual Screening and Validation of a SARS-CoV-2 Main Protease Noncovalent Inhibitor</a> published in <a href="https://pubs.acs.org/doi/10.1021/acs.jcim.1c00851">Journal of Chemical Information and Modeling</a>. Congratulations!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 6, 2021</th>
          <td>
            
              Please check out the <a href="https://zhuozhaoli.github.io/openings/">opening</a> for Collaborative PhD Programs between Southern University of Science and Technology and the Hong Kong Polytechnic University, 2022.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 3, 2021</th>
          <td>
            
              <a href="https://conferences.computer.org/iotDI/2022/">IoTDI 2022</a> is open for submission now. Please refer to the <a href="https://conferences.computer.org/iotDI/2022/cfp.html">CFPs</a> for more details. The abstract deadline is October 22, 2021
and the paper submission deadline is October 29, 2021, AoE.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Aug 3, 2021</th>
          <td>
            
              I started my new position as an Assistant Professor at SUSTech!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 22, 2021</th>
          <td>
            
              Our paper entitled <a href="/assets/pdf/HPDC-skluzacek-xtract-2021.pdf">A serverless framework for bulk metadata extraction</a> was accepted to <a href="http://www.hpdc.org/2021/program/">HPDC 2021</a>. Congratulations!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 24, 2021</th>
          <td>
            
              Our paper entitled <a href="/assets/pdf/IPDPS-shaffer-lfm-2021.pdf">Lightweight Function Monitors for Fine-grained Management in Large Scale Python applications</a> was accepted to <a href="https://www.ipdps.org/ipdps2021/2021-advance-program.html">IPDPS 2021</a>. Congratulations!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 24, 2021</th>
          <td>
            
              Our paper entitled <a href="/assets/pdf/IPDPSW-kumar-delta-2021.pdf">Coding the Continuum: Fluid Function Execution in Heterogeneous Computing Environments</a> was accepted to the <a href="http://hcw.oucreate.com/">Heterogeneity in Computing Workshop</a> at <a href="https://www.ipdps.org/ipdps2021/2021-advance-program.html">IPDPS 2021</a>. Congratulations!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 22, 2021</th>
          <td>
            
              Check out all the new features released in the <a href="https://funcx.readthedocs.io/en/latest/index.html">newest version of funcX</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 3, 2021</th>
          <td>
            
              Contributed to the U.S. Department of Energy National Virtual Biotechnology Laboratory Project about COVID-19, which was awarded the <a href="/assets/pdf/secretary-award-letter-of-acks-nvbl.pdf">Secretary of Energy Achievement Award</a> by Department of Engery.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 22, 2021</th>
          <td>
            
              Our paper entitled <a href="https://www.sciencedirect.com/science/article/pii/S0743731520303464">DLHub: Simplifying publication, discovery, and use of machine learning models in science</a> was accepted to JPDC 2021. Congratulations!

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Selected Publications (<u><a href="/publications">full list</a></u>)</h2>
  <h2 class="bibliography">2022</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TON</abbr>
    
  
  </div>

  <div id="li2022coscheduler" class="col-sm-10">
    
      <div class="title">Co-Scheduler: A Coflow-Aware Data-Parallel Job Scheduler in Hybrid Electrical/Optical Datacenter Networks</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Haiying Shen
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE/ACM Transactions on Networking,</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/9695973" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/TON-li-coscheduler-2022.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>To support higher demand for datacenter networks, networking researchers have proposed hybrid electrical/optical datacenter networks (Hybrid-DCN) that leverages optical circuit switching (OCS) along with traditional electrical packet switching (EPS). However, due to the high reconfiguration delay of OCS, OCS is used only for bulk data transfers between racks to amortize the reconfiguration delay. Existing job schedulers for data-parallel frameworks are not designed for Hybrid-DCN, since they neither place tasks to aggregate data traffic to take advantage of OCS, nor schedule tasks to minimize the Coflow completion time (CCT). In this paper, we describe the mismatch between existing job schedulers and the advanced Hybrid-DCN, introduce the requirements for the new scheduler, and present the implementation of Co-scheduler , a job scheduler for data-parallel frameworks that aims to improve job performance by placing the tasks of jobs to aggregate enough data traffic to better leverage OCS to minimize the CCT in Hybrid-DCN. Specifically, for every job, Co-scheduler computes guidelines on how many racks to place the job’s input data and the job’s tasks. The guidelines are dynamically generated based on the real-time job characteristics or predictable job characteristics from prior runs, with the aim of leveraging OCS whenever possible and efficient and minimizing CCT of jobs. Co-scheduler then schedules the tasks of jobs based on the guidelines. We evaluate the effectiveness of Co-scheduler using trace-driven simulation. The evaluation demonstrates that Co-scheduler can improve makespan, average job completion time, and average CCT of a workload by up to 56%, 61%, and 79%, respectively, compared to the state-of-the-art schedulers.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2022coscheduler</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Shen, Haiying}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/ACM Transactions on Networking}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Co-Scheduler: A Coflow-Aware Data-Parallel Job Scheduler in Hybrid Electrical/Optical Datacenter Networks}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1599-1612}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TNET.2022.3143232}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{TON}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/9695973}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{TON-li-coscheduler-2022.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TPDS</abbr>
    
  
  </div>

  <div id="li2022funcx" class="col-sm-10">
    
      <div class="title">funcX: Federated Function as a Service for Science</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ryan Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Yadu Babuji,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ben Galewsky,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Tyler J. Skluzacek,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Kirill Nagaitsev,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Anna Woodard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ben Blaiszik,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Josh Bryan,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Daniel S. Katz,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ian Foster,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Kyle Chard
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Parallel and Distributed Systems,</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/9899739" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/TPDS-li-funcx-2022.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>funcX is a distributed function as a service (FaaS) platform that enables flexible, scalable, and high performance remote function execution. Unlike centralized FaaS systems, funcX decouples the cloud-hosted management functionality from the edge-hosted execution functionality. funcX’s endpoint software can be deployed, by users or administrators, on arbitrary laptops, clouds, clusters, and supercomputers, in effect turning them into function serving systems. funcX’s cloud-hosted service provides a single location for registering, sharing, and managing both functions and endpoints. It allows for transparent, secure, and reliable function execution across the federated ecosystem of endpoints—enabling users to route functions to endpoints based on specific needs. funcX uses containers (e.g., Docker, Singularity, and Shifter) to provide common execution environments across endpoints. funcX implements various container management strategies to execute functions with high performance and efficiency on diverse funcX endpoints. funcX also integrates with an in-memory data store and Globus for managing data that may span endpoints. We motivate the need for funcX, present our prototype design and implementation, and demonstrate, via experiments on two supercomputers, that funcX can scale to more than 130000 concurrent workers. We show that funcX’s container warming-aware routing algorithm can reduce the completion time for 3,000 functions by up to 61% compared to a randomized algorithm and the in-memory data store can speed up data transfers by up to 3x compared to a shared file system.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2022funcx</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Chard, Ryan and Babuji, Yadu and Galewsky, Ben and Skluzacek, Tyler J. and Nagaitsev, Kirill and Woodard, Anna and Blaiszik, Ben and Bryan, Josh and Katz, Daniel S. and Foster, Ian and Chard, Kyle}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Parallel and Distributed Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{funcX: Federated Function as a Service for Science}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{33}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4948-4963}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TPDS.2022.3208767}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{TPDS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/9899739}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{TPDS-li-funcx-2022.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">JCIM</abbr>
    
  
  </div>

  <div id="clyde2021high" class="col-sm-10">
    
      <div class="title">High Throughput Virtual Screening and Validation of a SARS-CoV-2 Main Protease Non-Covalent Inhibitor</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                
                  Austin Clyde,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Stephanie Galanie,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Daniel W. Kneller,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Heng Ma,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Yadu Babuji,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ben Blaiszik,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Alexander Brace,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Thomas Brettin,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Kyle Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ryan Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Leighton Coates,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ian Foster,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Darin Hauner,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Vilmos Kertesz,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Neeraj Kumar,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Hyungro Lee,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Andre Merzky,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Jurgen G. Schmidt,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Li Tan,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Mikhail Titov,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Anda Trifan,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Matteo Turilli,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Hubertus Van Dam,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Srinivas C. Chennubhotla,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Shantenu Jha,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Andrey Kovalevsky,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Arvind Ramanathan,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Martha S. Head,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Rick Stevens
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Journal of Chemical Information and Modeling,</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://doi.org/10.1021/acs.jcim.1c00851" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/JCIM-clyde-screening-2022.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite the recent availability of vaccines against the acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the search for inhibitory therapeutic agents has assumed importance especially in the context of emerging new viral variants. In this paper, we describe the discovery of a novel non-covalent small-molecule inhibitor, MCULE-5948770040, that binds to and inhibits the SARS-Cov-2 main protease (Mpro) by employing a scalable high throughput virtual screening (HTVS) framework and a targeted compound library of over 6.5 million molecules that could be readily ordered and purchased. Our HTVS framework leverages the U.S. supercomputing infrastructure achieving nearly 91% resource utilization and nearly 126 million docking calculations per hour. Downstream biochemical assays validate this Mpro inhibitor with an inhibition constant (Ki) of 2.9 \textmuM [95% CI 2.2, 4.0]. Further, using room-temperature X-ray crystallography, we show that MCULE-5948770040 binds to a cleft in the primary binding site of Mpro forming stable hydrogen bond and hydrophobic interactions. We then used multiple \textmus-timescale molecular dynamics (MD) simulations, and machine learning (ML) techniques to elucidate how the bound ligand alters the conformational states accessed by Mpro, involving motions both proximal and distal to the binding site. Together, our results demonstrate how MCULE-5948770040 inhibits Mpro and offers a springboard for further therapeutic design.Significance StatementSignificance Statement The ongoing novel coronavirus pandemic (COVID-19) has prompted a global race towards finding effective therapeutics that can target the various viral proteins. Despite many virtual screening campaigns in development, the discovery of validated inhibitors for SARS-CoV-2 protein targets has been limited. We discover a novel inhibitor against the SARS-CoV-2 main protease. Our integrated platform applies downstream biochemical assays, X-ray crystallography, and atomistic simulations to obtain a comprehensive characterization of its inhibitory mechanism. Inhibiting Mpro can lead to significant biomedical advances in targeting SARS-CoV-2 treatment, as it plays a crucial role in viral replication.Competing Interest StatementThe authors have declared no competing interest.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">clyde2021high</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Clyde, Austin and Galanie, Stephanie and Kneller, Daniel W. and Ma, Heng and Babuji, Yadu and Blaiszik, Ben and Brace, Alexander and Brettin, Thomas and Chard, Kyle and Chard, Ryan and Coates, Leighton and Foster, Ian and Hauner, Darin and Kertesz, Vilmos and Kumar, Neeraj and Lee, Hyungro and Li, Zhuozhao and Merzky, Andre and Schmidt, Jurgen G. and Tan, Li and Titov, Mikhail and Trifan, Anda and Turilli, Matteo and Van Dam, Hubertus and Chennubhotla, Srinivas C. and Jha, Shantenu and Kovalevsky, Andrey and Ramanathan, Arvind and Head, Martha S. and Stevens, Rick}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{High Throughput Virtual Screening and Validation of a SARS-CoV-2 Main Protease Non-Covalent Inhibitor}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Chemical Information and Modeling}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{62}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{116-128}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1021/acs.jcim.1c00851}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{PMID: 34793155}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1021/acs.jcim.1c00851}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{JCIM}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{JCIM-clyde-screening-2022.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2021</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IPDPS</abbr>
    
  
  </div>

  <div id="shaffer2021lightweight" class="col-sm-10">
    
      <div class="title">Lightweight Function Monitors for Fine-Grained Management in Large Scale Python Applications</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                
                  Tim Shaffer,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ben Tovar,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Yadu Babuji,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  TJ Dasso,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Zoe Surma,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Kyle Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ian Foster,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Douglas Thain
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS),</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/9460530" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/IPDPS-shaffer-lfm-2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Python has become a widely used programming language for research, not only for small one-off analyses, but also for complex application pipelines running at supercomputer-scale. Modern parallel programming frameworks for Python present users with a more granular unit of management than traditional Unix processes and batch submissions: the Python function. We review the challenges involved in running native Python functions at scale, and present techniques for dynamically determining a minimal set of dependencies and for assembling a lightweight function monitor (LFM) that captures the software environment and manages resources at the granularity of single functions. We evaluate these techniques in a range of environments, from campus cluster to supercomputer, and show that our advanced dependency management planning and dynamic resource management methods provide superior performance and utilization relative to coarser-grained management approaches, achieving several-fold decrease in execution time for several large Python applications.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shaffer2021lightweight</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shaffer, Tim and Li, Zhuozhao and Tovar, Ben and Babuji, Yadu and Dasso, TJ and Surma, Zoe and Chard, Kyle and Foster, Ian and Thain, Douglas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Lightweight Function Monitors for Fine-Grained Management in Large Scale Python Applications}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{786-796}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IPDPS49936.2021.00088}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/9460530}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{IPDPS-shaffer-lfm-2021.pdf}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1530-2075}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{IPDPS}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">JPDC</abbr>
    
  
  </div>

  <div id="li2021dlhub" class="col-sm-10">
    
      <div class="title">DLHub: Simplifying publication, discovery, and use of machine learning models in science</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ryan Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Logan Ward,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Kyle Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Tyler J. Skluzacek,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Yadu Babuji,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Anna Woodard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Steven Tuecke,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ben Blaiszik,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Michael J. Franklin,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Ian Foster
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Journal of Parallel and Distributed Computing,</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S0743731520303464" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/JPDC-li-dlhub-2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Machine Learning (ML) has become a critical tool enabling new methods of analysis and driving deeper understanding of phenomena across scientific disciplines. There is a growing need for “learning systems” to support various phases in the ML lifecycle. While others have focused on supporting model development, training, and inference, few have focused on the unique challenges inherent in science, such as the need to publish and share models and to serve them on a range of available computing resources. In this paper, we present the Data and Learning Hub for science (DLHub), a learning system designed to support these use cases. Specifically, DLHub enables publication of models, with descriptive metadata, persistent identifiers, and flexible access control. It packages arbitrary models into portable servable containers, and enables low-latency, distributed serving of these models on heterogeneous compute resources. We show that DLHub supports low-latency model inference comparable to other model serving systems including TensorFlow Serving, SageMaker, and Clipper, and improved performance, by up to 95%, with batching and memoization enabled. We also show that DLHub can scale to concurrently serve models on 500 containers. Finally, we describe five case studies that highlight the use of DLHub for scientific applications.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2021dlhub</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DLHub: Simplifying publication, discovery, and use of machine learning models in science}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Parallel and Distributed Computing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{147}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{64-76}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0743-7315}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.jpdc.2020.08.006}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0743731520303464}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Chard, Ryan and Ward, Logan and Chard, Kyle and Skluzacek, Tyler J. and Babuji, Yadu and Woodard, Anna and Tuecke, Steven and Blaiszik, Ben and Franklin, Michael J. and Foster, Ian}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Learning systems, Model serving, Machine learning, DLHub}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{JPDC}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{JPDC-li-dlhub-2021.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2020</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">HPDC</abbr>
    
  
  </div>

  <div id="chard2020funcx" class="col-sm-10">
    
      <div class="title">FuncX: A Federated Function Serving Fabric for Science</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                
                  Ryan Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Yadu Babuji,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Tyler Skluzacek,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Anna Woodard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ben Blaiszik,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ian Foster,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Kyle Chard
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing,</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://doi.org/10.1145/3369583.3392683" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/HPDC-chard-funcx-2020.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Exploding data volumes and velocities, new computational methods and platforms, and
ubiquitous connectivity demand new approaches to computation in the sciences. These
new approaches must enable computation to be mobile, so that, for example, it can
occur near data, be triggered by events (e.g., arrival of new data), be offloaded
to specialized accelerators, or run remotely where resources are available. They also
require new design approaches in which monolithic applications can be decomposed into
smaller components, that may in turn be executed separately and on the most suitable
resources. To address these needs we present funcX—a distributed function as a service
(FaaS) platform that enables flexible, scalable, and high performance remote function
execution. funcX’s endpoint software can transform existing clouds, clusters, and
supercomputers into function serving systems, while funcX’s cloud-hosted service provides
transparent, secure, and reliable function execution across a federated ecosystem
of endpoints. We motivate the need for funcX with several scientific case studies,
present our prototype design and implementation, show optimizations that deliver throughput
in excess of 1 million functions per second, and demonstrate, via experiments on two
supercomputers, that funcX can scale to more than more than 130 000 concurrent workers.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chard2020funcx</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chard, Ryan and Babuji, Yadu and Li, Zhuozhao and Skluzacek, Tyler and Woodard, Anna and Blaiszik, Ben and Foster, Ian and Chard, Kyle}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FuncX: A Federated Function Serving Fabric for Science}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450370523}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3369583.3392683}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3369583.3392683}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{65–76}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{federated function serving, function as a service, funcX}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Stockholm, Sweden}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{HPDC '20}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{HPDC}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{HPDC-chard-funcx-2020.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="babuji2020targeting" class="col-sm-10">
    
      <div class="title">Targeting SARS-CoV-2 with AI-and HPC-enabled lead generation: a first data release</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                
                  Yadu Babuji,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ben Blaiszik,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Tom Brettin,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Kyle Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ryan Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Austin Clyde,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ian Foster,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Zhi Hong,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Shantenu Jha,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and  others
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2006.02431,</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://arxiv.org/abs/2006.02431" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Researchers across the globe are seeking to rapidly repurpose existing drugs or discover new drugs to counter the the novel coronavirus disease (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). One promising approach is to train machine learning (ML) and artificial intelligence (AI) tools to screen large numbers of small molecules. As a contribution to that effort, we are aggregating numerous small molecules from a variety of sources, using high-performance computing (HPC) to computer diverse properties of those molecules, using the computed properties to train ML/AI models, and then using the resulting models for screening. In this first data release, we make available 23 datasets collected from community sources representing over 4.2 B molecules enriched with pre-computed: 1) molecular fingerprints to aid similarity searches, 2) 2D images of molecules to enable exploration and application of image-based deep learning methods, and 3) 2D and 3D molecular descriptors to speed development of machine learning models. This data release encompasses structural information on the 4.2 B molecules and 60 TB of pre-computed data. Future releases will expand the data to include more detailed molecular simulations, computed models, and other products.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">babuji2020targeting</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Targeting SARS-CoV-2 with AI-and HPC-enabled lead generation: a first data release}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Babuji, Yadu and Blaiszik, Ben and Brettin, Tom and Chard, Kyle and Chard, Ryan and Clyde, Austin and Foster, Ian and Hong, Zhi and Jha, Shantenu and Li, Zhuozhao and others}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2006.02431}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">status</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2006.02431}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICPP</abbr>
    
  
  </div>

  <div id="li2020impact" class="col-sm-10">
    
      <div class="title">Impact of Memory DoS Attacks on Cloud Applications and Real-Time Detection Schemes</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Tanmoy Sen,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Haiying Shen,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Mooi Choo Chuah
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 49th International Conference on Parallel Processing - ICPP,</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://doi.org/10.1145/3404397.3404465" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/ICPP-li-mdos-2020.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Even though memory-based denial-of-service attacks can cause severe performance degradations
on co-located virtual machines, a previous detection scheme against such attacks cannot
accurately detect the attacks and also generates high detection delay and high performance
overhead since it assumes that cache-related statistics of an application follow the
same probability distribution at all times, which may not be true for all types of
applications. In this paper, we present the experimental results showing the impacts
of memory DoS attacks on different types of cloud-based applications. Based on these
results, we propose two lightweight, responsive Statistical based Detection Schemes
(SDS/B and SDS/P) that can detect such attacks accurately. SDS/B constructs a profile
of normal range of cache-related statistics for all applications and use statistical
methods to infer an attack when the real-time collected statistics exceed this normal
range, while SDS/P exploits the increased periods of access patterns for periodic
applications to infer an attack. Our evaluation results show that SDS/B and SDS/P
outperform the state-of-the-art detection scheme, e.g., with 65% higher specificity,
40% shorter detection delay, and 7% less performance overhead.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2020impact</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Sen, Tanmoy and Shen, Haiying and Chuah, Mooi Choo}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Impact of Memory DoS Attacks on Cloud Applications and Real-Time Detection Schemes}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450388160}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3404397.3404465}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3404397.3404465}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{49th International Conference on Parallel Processing - ICPP}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{67}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{detection schemes, memory Denial-of-Service attack, virtual machine}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Edmonton, AB, Canada}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ICPP '20}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICPP}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{ICPP-li-mdos-2020.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CIKM</abbr>
    
  
  </div>

  <div id="qiu2020time" class="col-sm-10">
    
      <div class="title">Time-Efficient Geo-Obfuscation to Protect Worker Location Privacy over Road Networks in Spatial Crowdsourcing</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                
                  Chenxi Qiu,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Anna Squicciarini,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ce Pang,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Li Yan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://doi.org/10.1145/3340531.3411863" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/CIKM-qiu-obfuscation-2020.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>To promote cost-effective task assignment in Spatial Crowdsourcing (SC), workers are
required to report their location to servers, which raises serious privacy concerns.
As a solution, geo-obfuscation has been widely used to protect the location privacy
of SC workers, where workers are allowed to report perturbed location instead of the
true location. Yet, most existing geo-obfuscation methods consider workers? mobility
on a 2 dimensional (2D) plane, wherein workers can move in arbitrary directions. Unfortunately,
2D-based geo-obfuscation is likely to generate high traveling cost for task assignment
over roads, as it cannot accurately estimate the traveling costs distortion caused
by location obfuscation. In this paper, we tackle the SC worker location privacy problem
over road networks. Considering the network-constrained mobility features of workers,
we describe workers? mobility by a weighted directed graph, which considers the dynamic
traffic condition and road network topology. Based on the graph model, we design a
geo-obfuscation (GO) function for workers to maximize the workers? overall location
privacy without compromising the task assignment efficiency. We formulate the problem
of deriving the optimal GO function as a linear programming (LP) problem. By using
the angular block structure of the LP’s constraint matrix, we apply Dantzig-Wolfe
decomposition to improve the time-efficiency of the GO function generation. Our experimental
results in the real-trace driven simulation and the real-world experiment demonstrate
the effectiveness of our approach in terms of both privacy and task assignment efficiency.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">qiu2020time</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Qiu, Chenxi and Squicciarini, Anna and Li, Zhuozhao and Pang, Ce and Yan, Li}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Time-Efficient Geo-Obfuscation to Protect Worker Location Privacy over Road Networks in Spatial Crowdsourcing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450368599}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3340531.3411863}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3340531.3411863}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 29th ACM International Conference on Information &amp;amp; Knowledge Management}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1275–1284}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{geo-obfuscation, location privacy, spatial crowdsourcing}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Virtual Event, Ireland}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CIKM '20}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CIKM}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{CIKM-qiu-obfuscation-2020.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2019</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICDCS</abbr>
    
  
  </div>

  <div id="li2019co" class="col-sm-10">
    
      <div class="title">Co-scheduler: Accelerating Data-Parallel Jobs in Datacenter Networks with Optical Circuit Switching</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Haiying Shen
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS),</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/8885103" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/ICDCS-li-coscheduler-2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The optical circuit switch (OCS) in recently proposed hybrid electrical/optical datacenter networks (Hybrid-DCN) can only be used to transfer large flows (i.e., flows with a large size of data). Current job schedulers for data-parallel frameworks are not suitable for Hybrid-DCN, since they neither place tasks to aggregate data traffic to take advantage of OCS nor schedule tasks to minimize the Coflow completion time (CCT). In this paper, we propose Co-scheduler, a job scheduler for dataparallel frameworks that aims to improve job performance by attempting to place the tasks of a job to aggregate enough data traffic to take advantage of OCS and minimize the CCT in Hybrid-DCN. Specifically, for each job, Co-scheduler computes a guideline on the number of racks to place the job’s input data and to run the job’s map tasks, so that the job can potentially take full advantage of OCS to transfer its data. When the map tasks of a job complete, Co-scheduler computes all the possible schedules of the reduce tasks of the job. Each possible schedule includes the number of racks to schedule the reduce tasks that enables the job to use OCS to transfer its data, and the number of reduce tasks to place on each of the racks that minimizes CCT of the job. Next, Co-scheduler selects a best schedule among all the possible schedules so that the job completion time is minimized. Finally, Co-scheduler schedules the map tasks and reduce tasks of the job based on the computed guideline and best schedule. The evaluation demonstrates that compared to the state-of-theart schedulers, Co-scheduler achieves performance improvements on makespan, average job completion time, and average CCT by up to 51.2%, 54.6% and 73.6%, respectively.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2019co</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Shen, Haiying}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Co-scheduler: Accelerating Data-Parallel Jobs in Datacenter Networks with Optical Circuit Switching}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{186-195}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICDCS.2019.00027}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2575-8411}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICDCS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/8885103}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{ICDCS-li-coscheduler-2019.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">HPDC</abbr>
    
  
  </div>

  <div id="babuji2019parsl" class="col-sm-10">
    
      <div class="title">Parsl: Pervasive Parallel Programming in Python</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                
                  Yadu Babuji,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Anna Woodard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Daniel S. Katz,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ben Clifford,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Rohan Kumar,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Lukasz Lacinski,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ryan Chard,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Justin M. Wozniak,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ian Foster,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Michael Wilde,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Kyle Chard
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing,</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://doi.org/10.1145/3307681.3325400" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/HPDC-babuji-parsl-2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>High-level programming languages such as Python are increasingly used to provide intuitive
interfaces to libraries written in lower-level languages and for assembling applications
from various components. This migration towards orchestration rather than implementation,
coupled with the growing need for parallel computing (e.g., due to big data and the
end of Moore’s law), necessitates rethinking how parallelism is expressed in programs.
Here, we present Parsl, a parallel scripting library that augments Python with simple,
scalable, and flexible constructs for encoding parallelism. These constructs allow
Parsl to construct a dynamic dependency graph of components that it can then execute
efficiently on one or many processors. Parsl is designed for scalability, with an
extensible set of executors tailored to different use cases, such as low-latency,
high-throughput, or extreme-scale execution. We show, via experiments on the Blue
Waters supercomputer, that Parsl executors can allow Python scripts to execute components
with as little as 5 ms of overhead, scale to more than 250000 workers across more
than 8000 nodes, and process upward of 1200 tasks per second. Other Parsl features
simplify the construction and execution of composite programs by supporting elastic
provisioning and scaling of infrastructure, fault-tolerant execution, and integrated
wide-area data management. We show that these capabilities satisfy the needs of many-task,
interactive, online, and machine learning applications in fields such as biology,
cosmology, and materials science.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">babuji2019parsl</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Babuji, Yadu and Woodard, Anna and Li, Zhuozhao and Katz, Daniel S. and Clifford, Ben and Kumar, Rohan and Lacinski, Lukasz and Chard, Ryan and Wozniak, Justin M. and Foster, Ian and Wilde, Michael and Chard, Kyle}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Parsl: Pervasive Parallel Programming in Python}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450366700}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3307681.3325400}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3307681.3325400}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{25–36}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{parsl, parallel programming, python}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Phoenix, AZ, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{HPDC '19}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{HPDC}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{HPDC-babuji-parsl-2019.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICPP</abbr>
    
  
  </div>

  <div id="li2019jobpacker" class="col-sm-10">
    
      <div class="title">JobPacker: Job Scheduling for Data-Parallel Frameworks with Hybrid Electrical/Optical Datacenter Networks</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Haiying Shen
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 48th International Conference on Parallel Processing,</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://doi.org/10.1145/3337821.3337880" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/ICPP-li-jobpacker-2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In spite of many advantages of hybrid electrical/optical datacenter networks (Hybrid-DCN),
current job schedulers for data-parallel frameworks are not suitable for Hybrid-DCN,
since the schedulers do not aggregate data traffic to facilitate using optical circuit
switch (OCS). In this paper, we propose JobPacker, a job scheduler for data-parallel
frameworks in Hybrid-DCN that aims to take full advantage of OCS to improve job performance.
JobPacker aggregates the data transfers of a job in order to use OCS to improve data
transfer efficiency. It first explores the tradeoff between parallelism and traffic
aggregation for each shuffle-heavy recurring job, and then generates an offline schedule
including which racks to run each job and the sequence to run the recurring jobs in
each rack that yields the best performance. It has a new sorting method to prioritize
recurring jobs in offline-scheduling to prevent high resource contention while fully
utilizing cluster resources. In real-time scheduler, JobPacker uses the offline schedule
to guide the data placement and schedule recurring jobs, and schedules non-recurring
jobs to the idle resources not assigned to recurring jobs. Trace-driven simulation
and GENI-based emulation show that JobPacker reduces the makespan up to 49% and the
median completion time up to 43%, compared to the state-of-the-art schedulers in Hybrid-DCN.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2019jobpacker</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Shen, Haiying}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{JobPacker: Job Scheduling for Data-Parallel Frameworks with Hybrid Electrical/Optical Datacenter Networks}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450362955}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3337821.3337880}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3337821.3337880}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 48th International Conference on Parallel Processing}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Kyoto, Japan}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ICPP 2019}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICPP}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{ICPP-li-jobpacker-2019.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2018</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICDCS</abbr>
    
  
  </div>

  <div id="li2018pagerankvm" class="col-sm-10">
    
      <div class="title">PageRankVM: A PageRank Based Algorithm with Anti-Collocation Constraints for Virtual Machine Placement in Cloud Datacenters</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Haiying Shen,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Cole Miles
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS),</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/8416331" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/ICDCS-li-pagerankvm-2018.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>There is a dramatic increase in the variety of virtual machines (VMs) and complexity of VM placement problems in clouds. Previous VM placement approaches attempt to accommodate more VMs efficiently on fewer PMs by balancing the resource usages across multiple dimensions. However, these approaches are not sufficiently accurate in measuring the quality of the PMs in terms of fully utilizing PM resource and having the potential to accommodate more VMs. Therefore, it is critical to design a new method that can more accurately measure the probability of a PM of fully utilizing its resources after accommodating a given VM with the consideration of different types of VMs. In addition, anti-collocation constraints must be handled efficiently. We propose a PageRank based VM placement algorithm with anti-collocation constraints (PageRankVM). PageRankVM defines the best PM resource usage profile, which means that the PM has full resource utilization for every resource dimension, and then ranks PM profiles according to their convergence of transferring (by accommodating VMs) to the best profile. PageRankVM then places a given VM to the PM based on the ranks of the resulted PM profiles after accommodating the VM with the consideration of anti-collocation constraints. Compared to previous approaches, PageRankVM effectively measures the ability of different PM profiles to reach the best profiles by accommodating a given VM, and hence differentiates the effectiveness of different VM placement decisions. We conducted extensive trace-driven simulation and GENI testbed experiments and demonstrated that PageRankVM has superior performance compared with other methods in terms of reducing the number of PMs, the energy consumption, the number of VM migrations, and the service level objective (SLO) violations.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2018pagerankvm</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Shen, Haiying and Miles, Cole}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PageRankVM: A PageRank Based Algorithm with Anti-Collocation Constraints for Virtual Machine Placement in Cloud Datacenters}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{634-644}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICDCS.2018.00068}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2575-8411}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICDCS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/8416331}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{ICDCS-li-pagerankvm-2018.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">UbiComp</abbr>
    
  
  </div>

  <div id="yan2018employing" class="col-sm-10">
    
      <div class="title">Employing Opportunistic Charging for Electric Taxicabs to Reduce Idle Time</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                
                  Li Yan,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Haiying Shen,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Ankur Sarker,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  John A. Stankovic,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Chenxi Qiu,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Juanjuan Zhao,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Chengzhong Xu
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://doi.org/10.1145/3191779" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/UbiComp-yan-employing-2018.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>For electric taxicabs, the idle time spent on cruising for passengers, seeking chargers,
and charging is wasteful. Previous works can only save cruising time through better
routing, or charger seeking and charging time through proper charger deployment, but
not for both. With the advancement of wireless charging techniques, efficient opportunistic
charging of electric vehicles at their parked positions becomes possible. This enables
a taxicab to get charged while waiting for the next passenger. In this paper, we present
an opportunistic wireless charger deployment scheme in a city, which both maximizes
the taxicabs’ opportunity of picking up passengers at the chargers and supports the
taxicabs’ continuous operability on roads, while minimizing the total deployment cost.
We studied a metropolitan-scale taxicab dataset on several factors important for deploying
wireless chargers and determining the numbers of the chargers in the regions: the
number of passengers, the functionalities of buildings, and the frequency of passenger
appearance in a region, and taxicab traffic flows in a city. Then, we formulate a
multi-objective optimization problem and find the solution. Our trace-driven experiments
demonstrate the superior performance of our scheme over other representative methods
in terms of reducing idle time and supporting the operability of the taxicabs.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yan2018employing</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yan, Li and Shen, Haiying and Li, Zhuozhao and Sarker, Ankur and Stankovic, John A. and Qiu, Chenxi and Zhao, Juanjuan and Xu, Chengzhong}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Employing Opportunistic Charging for Electric Taxicabs to Reduce Idle Time}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{March 2018}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3191779}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3191779}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{47}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{mobile data analysis, kernel density estimation, Vehicle wireless charging, charger deployment}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{UbiComp}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{UbiComp-yan-employing-2018.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2017</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TPDS</abbr>
    
  
  </div>

  <div id="li2017measuring" class="col-sm-10">
    
      <div class="title">Measuring Scale-Up and Scale-Out Hadoop with Remote and Local File Systems and Selecting the Best Platform</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Haiying Shen
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Parallel and Distributed Systems,</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/7940040" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/TPDS-li-measurement-2017.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>MapReduce is a popular computing model for parallel data processing on large-scale datasets, which can vary from gigabytes to terabytes and petabytes. Though Hadoop MapReduce normally uses Hadoop Distributed File System (HDFS) local file system, it can be configured to use a remote file system. Then, an interesting question is raised: for a given application, which is the best running platform among the different combinations of scale-up and scale-out Hadoop with remote and local file systems. However, there has been no previous research on how different types of applications (e.g., CPU-intensive, data-intensive) with different characteristics (e.g., input data size) can benefit from the different platforms. Thus, in this paper, we conduct a comprehensive performance measurement of different applications on scale-up and scale-out clusters configured with HDFS and a remote file system (i.e., OFS), respectively. We identify and study how different job characteristics (e.g., input data size, the number of file reads/writes, and the amount of computations) affect the performance of different applications on the different platforms. Based on the measurement results, we also propose a performance prediction model to help users select the best platforms that lead to the minimum latency. Our evaluation using a Facebook workload trace demonstrates the effectiveness of our prediction model. This study is expected to provide a guidance for users to choose the best platform to run different applications with different characteristics in the environment that provides both remote and local storage, such as HPC cluster and cloud environment.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2017measuring</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Shen, Haiying}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Parallel and Distributed Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Measuring Scale-Up and Scale-Out Hadoop with Remote and Local File Systems and Selecting the Best Platform}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3201-3214}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TPDS.2017.2712635}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-2183}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{TPDS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/7940040}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{TPDS-li-measurement-2017.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TPDS</abbr>
    
  
  </div>

  <div id="li2017exploration" class="col-sm-10">
    
      <div class="title">An Exploration of Designing a Hybrid Scale-Up/Out Hadoop Architecture Based on Performance Measurements</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Haiying Shen,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  Walter Ligon,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Jeffrey Denton
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Parallel and Distributed Systems,</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/7480403" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/TPDS-li-hybrid-2016.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Scale-up machines perform better for jobs with small and median (KB, MB) data sizes, while scale-out machines perform better for jobs with large (GB, TB) data size. Since a workload usually consists of jobs with different data size levels, we propose building a hybrid Hadoop architecture that includes both scale-up and scale-out machines, which however is not trivial. The first challenge is workload data storage. Thousands of small data size jobs in a workload may overload the limited local disks of scale-up machines. Jobs from scale-up and scale-out machines may both request the same set of data, which leads to data transmission between the machines. The second challenge is to automatically schedule jobs to either scale-up or scale-out cluster to achieve the best performance. We conduct a thorough performance measurement of different applications on scale-up and scale-out clusters, configured with Hadoop Distributed File System (HDFS) and a remote file system (i.e., OFS), respectively. We find that using OFS rather than HDFS can solve the data storage challenge. Also, we identify the factors that determine the performance differences on the scale-up and scale-out clusters and their cross points to make the choice. Accordingly, we design and implement the hybrid scale-up/out Hadoop architecture. Our trace-driven experimental results show that our hybrid architecture outperforms both the traditional Hadoop architecture with HDFS and with OFS in terms of job completion time, throughput and job failure rate.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2017exploration</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Shen, Haiying and Ligon, Walter and Denton, Jeffrey}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Parallel and Distributed Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Exploration of Designing a Hybrid Scale-Up/Out Hadoop Architecture Based on Performance Measurements}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{386-400}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TPDS.2016.2573820}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-2183}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{TPDS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/7480403}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{TPDS-li-hybrid-2016.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2016</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TPDS</abbr>
    
  
  </div>

  <div id="shen2016new" class="col-sm-10">
    
      <div class="title">New Bandwidth Sharing and Pricing Policies to Achieve a Win-Win Situation for Cloud Provider and Tenants</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                
                  Haiying Shen,
                
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                and <em>Zhuozhao Li</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Parallel and Distributed Systems,</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/7317795" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/TPDS-shen-winwin-2016.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>For predictable application performance or fairness in network sharing in clouds, many bandwidth allocation policies have been proposed. However, with these policies, tenants are not incentivized to use idle bandwidth or prevent link congestion, and may even take advantage of the policies to gain unfair bandwidth allocation. Increasing network utilization while avoiding congestion not only benefits cloud provider but also the tenants by improving application performance. In this paper, we propose a new pricing model that sets different unit prices for reserved bandwidth, the bandwidth on congested links and on uncongested links, and makes the unit price for congested links proportional to their congestion degrees. We use game theory model to analyze tenants’ behaviors in our model and the current pricing models, which shows the effectiveness of our model in providing the incentives. With the pricing model, we propose a network sharing policy to achieve both min-guarantee and proportionality, while prevent tenants from earning unfair bandwidth. We further propose methods for each virtual machine to arrange its traffic to reduce its unsatisfied demand and maximize its utility, while increase network utilization. As a result, our solution creates a win-win situation, where tenants strive to increase their benefits in bandwidth sharing, which also concurrently increases the utilities of cloud provider and other tenants. Our simulation and trace-driven experimental results show the effectiveness of our solutions in creating the win-win situation.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">shen2016new</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shen, Haiying and Li, Zhuozhao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Parallel and Distributed Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{New Bandwidth Sharing and Pricing Policies to Achieve a Win-Win Situation for Cloud Provider and Tenants}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{27}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2682-2697}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TPDS.2015.2497701}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-2183}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{TPDS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/7317795}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{TPDS-shen-winwin-2016.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2015</h2>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICPP</abbr>
    
  
  </div>

  <div id="li2015designing" class="col-sm-10">
    
      <div class="title">Designing a Hybrid Scale-Up/Out Hadoop Architecture Based on Performance Measurements for High Application Performance</div>
      <div class="author">
        
          
          
          
          
          
          
          
          
            
              
                <em>Zhuozhao Li</em>,
              
            
          
        
          
          
          
          
          
          
          
          
            
              
                
                  and Haiying Shen
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2015 44th International Conference on Parallel Processing,</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/7349557" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      
      <a href="/assets/pdf/ICPP-li-hybrid-2015.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Since scale-up machines perform better for jobs with small and median (KB, MB) data sizes while scale-out machines perform better for jobs with large (GB, TB) data size, and a workload usually consists of jobs with different data size levels, we propose building a hybrid Hadoop architecture that includes both scale-up and scale-out machines, which however is not trivial. The first challenge is workload data storage. Thousands of small data size jobs in a workload may overload the limited local disks of scale-up machines. Jobs from scale-up and scale-out machines may both request the same set of data, which leads to data transmission between the machines. The second challenge is to automatically schedule jobs to either scale-up or scale-out cluster to achieve the best performance. We conduct a thorough performance measurement of different applications on scale-up and scale-out clusters, configured with Hadoop Distributed File System (HDFS) and a remote file system (i.e., OFS), respectively. We find that using OFS rather than HDFS can solve the data storage challenge. Also, we identify the factors that determine the performance differences on the scale-up and scale-out clusters and their cross points to make the choice. Accordingly, we design and implement the hybrid scale-up/out Hadoop architecture. Our trace-driven experimental results show that our hybrid architecture outperforms both the traditional Hadoop architecture with HDFS and with OFS in terms of job completion time.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2015designing</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuozhao and Shen, Haiying}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2015 44th International Conference on Parallel Processing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Designing a Hybrid Scale-Up/Out Hadoop Architecture Based on Performance Measurements for High Application Performance}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{21-30}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICPP.2015.11}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0190-3918}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICPP}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/7349557}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{ICPP-li-hybrid-2015.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Zhuozhao  Li.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank">al-folio</a> theme.

    
    
    Last updated: February 17, 2025.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
